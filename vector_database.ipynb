{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e50750f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 35/35 [00:02<00:00, 14.65ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print preprocessed sentences\n",
      "(35115, 384)\n",
      "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x000001C4EF6EBD50> >\n",
      "\n",
      "\n",
      "Now Try an query to be solved\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "ds = load_dataset(\"mratanusarkar/Indian-Laws\")\n",
    "\n",
    "ds['train'].to_csv('train.csv')\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "sentences = df['act_title'].tolist()\n",
    "\n",
    "sentences.extend(df['section'].tolist())\n",
    "\n",
    "sentences.extend(df['law'].tolist())\n",
    "\n",
    "sentences = [word for word in list(set(sentences)) if type(word) is str]\n",
    "\n",
    "def preprocess_legal_text(text: str) -> str:\n",
    "    \"\"\"Clean and preprocess legal text\"\"\"\n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Remove page numbers and headers/footers\n",
    "    text = re.sub(r'\\n\\s*\\d+\\s*\\n', '\\n', text)\n",
    "\n",
    "    # Clean up common legal document artifacts\n",
    "    text = re.sub(r'_+', '', text)  # Remove underscores\n",
    "    text = re.sub(r'-{2,}', '', text)  # Remove multiple dashes\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "sentences = [preprocess_legal_text(word) for word in list(set(sentences)) if type(word) is str]\n",
    "print('Print preprocessed sentences')\n",
    "\n",
    "# initialize sentence transformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2',device=device)\n",
    "# create sentence embeddings\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "print(sentence_embeddings.shape)\n",
    "\n",
    "dim = sentence_embeddings.shape[1]\n",
    "\n",
    "# Build FAISS index\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(sentence_embeddings)\n",
    "print(index)\n",
    "print('\\n\\nNow Try an query to be solved')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34003678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Context:\n",
      " the aadhaar targeted delivery of financial and other subsidies benefits and services act   savings anything done or any action taken by the central government under the resolution of the government of india planning commission bearing notification number aadmin i dated the th january  or by the department of electronics and information technology under the cabinet secretariat notification bearing notification number so e dated the th september  as the case may be shall be deemed to have been validly done or taken under this act\n",
      "the aadhaar targeted delivery of financial and other subsidies benefits and services act   act to apply for offence or contravention committed outside india  subject to the provisions of subsection  the provisions of this act shall apply also to any offence or contravention committed outside india by any person irrespective of his nationality  for the purposes of subsection  the provisions of this act shall apply to any offence or contravention committed outside india by any person if the act or conduct constituting the offence or contravention involves any data in the central identities data repository\n",
      "the aadhaar targeted delivery of financial and other subsidies benefits and services act  chapter i preliminary  short title extent and commencement  this act may be called the aadhaar targeted delivery of financial and other subsidies benefits and services act   it shall extend to the whole of india  and save as otherwise provided in this act it shall also apply to any offence or contravention thereunder committed outside india by any person  it shall come into force on such date as the central government may by notification in the official gazette appoint and different dates may be appointed for different provisions of this act and any reference in any such provision to the commencement of this act shall be construed as a reference to the commencement of that provision\n",
      "aadhaar targeted delivery of financial and other subsidies benefits and services act\n",
      "the aadhaar targeted delivery of financial and other subsidies benefits and services act  chapter vii offences and penalties  penalty for impersonation at time of enrolment whoever impersonates or attempts to impersonate another person whether dead or alive real or imaginary by providing any false demographic information or biometric information shall be punishable with imprisonment for a term which may extend to three years or with a fine which may extend to ten thousand rupees or with both\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "query_embedding = model.encode([\"The aadhar act 1996\"], convert_to_tensor=True)\n",
    "query_embedding = query_embedding.cpu().detach().numpy()\n",
    "# Search in FAISS\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Option 1: retrieve from cleaned sentences\n",
    "retrieved_chunks = [sentences[idx] for idx in indices[0]]\n",
    "\n",
    "# Option 2: retrieve full dataframe row (comment out above if using this)\n",
    "# retrieved_chunks = [df.iloc[idx].to_dict() for idx in indices[0]]\n",
    "\n",
    "context = \"\\n\".join(map(str, retrieved_chunks))\n",
    "print(\"Retrieved Context:\\n\", context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f825383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
      "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found in the provided laws\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a free HuggingFace text-generation / summarization pipeline\n",
    "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "def ask_legal_question(query, k=5):\n",
    "    # 1. Encode query\n",
    "    query_embedding = model.encode([query])\n",
    "\n",
    "    # 2. Retrieve top-k results from FAISS\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    retrieved_chunks = [sentences[idx] for idx in indices[0]]\n",
    "\n",
    "    # 3. Build context\n",
    "    context = \"\\n\".join(retrieved_chunks)\n",
    "\n",
    "    # 4. Build prompt for open-source model\n",
    "    prompt = f\"\"\"\n",
    "    You are a legal assistant.\n",
    "    Use ONLY the following legal context to answer the query.\n",
    "    If the answer cannot be found, reply: \"Not found in the provided laws\".\n",
    "\n",
    "    Query: {query}\n",
    "    Context:\n",
    "    {context}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    # 5. Generate response\n",
    "    response = qa_pipeline(prompt, max_length=256, clean_up_tokenization_spaces=True)\n",
    "    return response[0][\"generated_text\"]\n",
    "\n",
    "# Example run\n",
    "print(ask_legal_question(\"The aadhar act 1996\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8616e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
